# SignSpeak - A Sign to Text Interconverter

An application developed in Flutter, aimed to expand the inclusivity of the deaf and mute communities in day-to-day conversations and interactions. With the ability to interconvert sign languages (ASL) into textual languages (English), this application is the solution to bridge the communication gap between differently abled persons.

## Description
Built on a FLutter frontend, and boasting a Convolutional Neural Network (Deep Learning model) as its backbone, it offers a small yet efficient mobile-based application to translate sign languages with ease. Trained on an American Sign Language (ASL) Dataset with a capability to recognise and categorise 26 different alphabets and 10-12 commonly used words in day-to-day speech.  

## Motivation
There has been an ever existing communication gap between an individual who can speak and a person with hearing or speaking impairments, since it is not expected for a common man to be aware of sign languages. More than that, the unavailability of a single universal sign language makes it difficult for people with these disabilities to communicate with each other, leading to their isolation.

## System diagram
![System Diagram](https://github.com/omkar3012/SignSpeak/blob/master/system_diagram.jpg?raw=true)

## Dataset
The training dataset can be found [here](https://www.kaggle.com/datasets/ayuraj/asl-dataset)

## Preview
![Home Screen](https://github.com/omkar3012/SignSpeak/blob/master/preview_1.jpg?raw=true)
![Sign-To-Text](https://github.com/omkar3012/SignSpeak/blob/master/preview_2.jpg?raw=true)
![Text-To-Sign](https://github.com/omkar3012/SignSpeak/blob/master/preview_3.jpg?raw=true)
![Sign-To-Sign](https://github.com/omkar3012/SignSpeak/blob/master/preview_4.jpg?raw=true)

## Future Scope
Currently trained on a modest dataset of a single sign language, SignSpeak offers the opportunity to expand the efficacy and applicability horizons of the system developed by incorporating even more robust Deep Learning models
